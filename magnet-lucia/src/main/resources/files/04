Climate warming during the course of the twenty-first century is projected to be between 1.0 and 3.7 °C depending on future greenhouse gas emissions, based on the ensemble-mean results of state-of-the-art Earth System Models (ESMs). Just how reliable are these projections, given the complexity of the climate system? The early history of climate research provides insight into the understanding and science needed to answer this question. We examine the mathematical quantifications of planetary energy budget developed by Svante Arrhenius (1859–1927) and Guy Stewart Callendar (1898–1964) and construct an empirical approximation of the latter, which we show to be successful at retrospectively predicting global warming over the course of the twentieth century. This approximation is then used to calculate warming in response to increasing atmospheric greenhouse gases during the twenty-first century, projecting a temperature increase at the lower bound of results generated by an ensemble of ESMs (as presented in the latest assessment by the Intergovernmental Panel on Climate Change). This result can be interpreted as follows. The climate system is conceptually complex but has at its heart the physical laws of radiative transfer. This basic, or “core” physics is relatively straightforward to compute mathematically, as exemplified by Callendar's calculations, leading to quantitatively robust projections of baseline warming. The ESMs include not only the physical core but also climate feedbacks that introduce uncertainty into the projections in terms of magnitude, but not sign: positive (amplification of warming). As such, the projections of end-of-century global warming by ESMs are fundamentally trustworthy: quantitatively robust baseline warming based on the well-understood physics of radiative transfer, with extra warming due to climate feedbacks. These projections thus provide a compelling case that global climate will continue to undergo significant warming in response to ongoing emissions of CO2 and other greenhouse gases to the atmosphere.

Previous article in issueNext article in issue
Keywords
Greenhouse effectGlobal warmingEarth System ModelsArrheniusCallendar
Introduction
Climate change is a major risk facing mankind. At the United Nations Climate Change Conference held in Paris at the end of last year, 195 countries agreed on a plan to reduce emissions of CO2 and other greenhouse gases, aiming to limit global temperature increase to well below 2 °C (relative to pre-industrial climate, meaning a future warming of less than 1.4 °C because temperature had already increased by 0.6 °C by the end of the twentieth century). The link between CO2 and climate warming has caught the attention of scientists and politicians, as well as the general public, via the well-known “greenhouse effect” (Figure 1). Solar radiation passes largely unhindered through the atmosphere, heating the Earth's surface. In turn, energy is re-emitted as infrared, much of which is absorbed by CO2 and water vapour in the atmosphere, which thus acts as a blanket surrounding the Earth. Without this natural greenhouse effect, the average surface temperature would plummet to about −21 °C,1 rather less pleasant than the 14 °C experienced today.


Download full-size image
Figure 1. The “greenhouse effect.” The radiative balance between incoming solar radiation (yellow arrows) and the absorption of re-emitted infrared radiation by the atmosphere (orange arrows) drive surface heating. Adapted from: IPCC, Climate Change 2007: The Physical Science Basis. Contribution of Working Group I to the Fourth Assessment Report of the Intergovernmental Panel on Climate Change (Cambridge: Cambridge University Press, 2007), 115.

The concentration of CO2 in the atmosphere is increasing year on year as we burn fossil fuels, which enhances the natural greenhouse effect and warms the planet. To what extent, then, must CO2 emissions be kept under control in order to restrict global temperature rise to within 2 °C? The projections of complex Earth System Models (ESMs) provide quantitative answers to this question. Run on supercomputers, these models integrate the many processes taking place in the atmosphere, on land and in the ocean. According to the Intergovernmental Panel on Climate Change (IPCC), the latest results of these models indicate that the temperature increase during the course of the twenty-first century will be between 1.0 and 3.7 °C, depending on the future emissions of greenhouse gases.2 Taking into consideration the statistical properties of the ensemble of ESMs, and past observed warming, projected global temperatures are likely to exceed 2 °C above pre-industrial times for higher emission scenarios, with “likely” being defined as with a probability between 66 and 100%. This threshold can, however, likely be avoided in a low emission scenario. What are we to make of such statements and just how trustworthy are these projections?

The climate system is considerably more complex than the simple greenhouse paradigm described above. System feedbacks include changes in the circulation of the atmosphere and ocean (redistributing heat around the globe), the melting of snow and ice (altering albedo: the reflection of solar radiation from the Earth's surface), sequestration of CO2 by plants, changes to the amount and types of clouds, and altered atmospheric water vapour (a warmer atmosphere holds more water), among others. The need to include all these processes, as well as the fact that objective quantification of associated uncertainties is problematic,3 provides an easy opportunity for misinformation and disharmony. The media struggle to accurately communicate climate science, often leading to an emphasis on confusion and uncertainty when presenting the climate change debate.4 In some instances, there has been direct criticism of the trustworthiness of the ESMs within the peer-reviewed literature. Gregor Betz, for example, remarks that “it's not even clear that discrete simulations yield individually plausible or relevant projections.”5

In this article, we delve into the history of climate science, notably the early “pen-and-paper” models of planetary energy budget by Svante Arrhenius (1859–1927) and Guy Stewart Callendar (1898–1964).6 Arrhenius was primarily interested in the causes of the ice ages, whereas Callendar is remembered for his work linking warming to human-made burning of fossil fuels, the so-called “Callendar Effect.”7 Both models illustrate the role of the “greenhouse” physics of radiative transfer (the passage and attenuation of radiation in the atmosphere by absorption and scattering) in global warming, in the absence of feedbacks (with the exception of water vapour). We construct an empirical approximation of Callendar's model and show that it successfully generates a retrospective forecast of warming during the twentieth century. The same model is then used to make projections of warming to the end of the current century and compared with equivalent simulations made by today's ESMs (which include a range of system feedbacks), as presented in the latest IPCC assessment report.8 Based on this comparison, we will conclude by presenting the case for the trustworthiness of ESMs as regards their projection of global warming during the twenty-first century.

Arrhenius: CO2 and the ice ages
During the eighteenth century, early geologists noticed that giant boulders, today known as “erratics,” were scattered across much of Europe, far beyond the Alpine mountains from which they originated. How did they get there? Noah's flood was one obvious suggestion. Or maybe they were the result of cataclysmic volcanic activity. The actual cause turned out to be as remarkable as it was profound. Jean de Charpentier, a mining engineer, travelled to the Rhône Valley in the 1830s and suggested that the huge blocks of granite he saw there had been transported from afar by glaciers. Soon afterwards, Louis Agassiz, the famous Swiss-born naturalist and geologist, proposed that great ice ages had gripped the Earth during the previous millions of years of its history.9 Deep valleys were carved into the landscape as large parts of Europe, North America, and South America were covered by expanding ice sheets and glaciers, carrying with them the mysterious boulders. Woolly mammoths, mastodons, and other wild animals roamed the surrounding areas, experiencing temperatures some five degrees colder than today.10

What, then, was the cause of changes in the temperature of the Earth sufficient to drive the ice ages? Even today, we do not have a full answer to this question, which lies in understanding the radiative balance of the Earth. One part of the story is deviations in the Earth's orbit, the so-called Milanković cycles.11 Another key factor is the composition of the atmosphere, giving rise to the proverbial ‘greenhouse.’ The basic concepts of planetary energy budget and the greenhouse effect were first put forward in the early nineteenth century by the French scientist Joseph Fourier,12 although he never mentioned greenhouses in his writing.13 Fourier recognised that the atmosphere is opaque to “dark heat” (infrared radiation), but he was unable to identify which components were responsible. A few decades later, John Tyndall, an Irish physicist working in London, discovered that infrared absorption is largely due to carbon dioxide and water vapour, based on a series of carefully designed laboratory experiments.14 Could it be, Tyndall thought, that variations in the atmospheric concentrations of CO2 and water vapour account for “all the mutations of climate which the researches of geologists reveal”?15 What was needed was quantitative proof, converting the results of the experimental work into mathematical equations.

The Swede Svante Arrhenius (Figure 2) is remembered for his work on the conductivities of electrolytes, a topic of research that would earn him the Nobel Prize for chemistry in 1903. Arrhenius was interested not only in chemistry, but in physics and mathematics also, and it was this combination of talents that led him to perhaps his greatest achievement: the construction of a quantitative mathematical analysis of the influence of CO2 on planetary energy budget, culminating in the publication of his famous paper, “On the influence of carbonic acid [CO2] in the air upon the temperature of the ground.”16 Arrhenius had accepted a lectureship in physics at the Högskola, Stockholm in 1891 and was appointed professor of physics four years later. He was also a founder member of the Stockholm Physics Society, which became a milieu of intellectual activity during their fortnightly meetings as scientists from far and wide debated a range of topics classed under the heading “cosmic physics”: physics, chemistry, meteorology, geology, astronomy, and astrophysics.17 The ice ages, and causes thereof, were inevitably a lively subject for discussion. Through these meetings, Arrhenius formed a close collaboration with his colleague, Arvid Högbom, a geologist who was interested in the geochemical carbon cycle of the Earth and in particular how atmospheric carbon dioxide is buffered by the ocean, vegetation on land, and the formation of carbonates and silicates by weathering (breakdown of rocks and minerals via contact with the environment).18 “An increase or decrease of the supply [of CO2] continued during geological periods,” Högbom remarked, “must conduce to remarkable alterations of the quantity of carbonic acid in the air.”19


Download full-size image
Figure 2. Svante Arrhenius in 1909. Credit: Wikimedia Commons.

The stage was set, and Arrhenius forged ahead with developing equations to quantify how widely atmospheric CO2 would have to vary in order to bring about changes to both colder and warmer climates sufficient to explain the ice ages. The calculations involved balancing the radiative heat budget (thereby assuming a state of equilibrium), namely solar radiation arriving at the Earth's surface (including the effect of albedo from clouds and the Earth's surface) and the subsequent absorption of re-emitted infrared radiation by the atmosphere. Calculating this absorption required integration across the different wavelengths that encompass the absorption spectrum of CO2 and water vapour, as well as integrating across different zenith angles (the distance from vertical at which sunlight strikes the atmosphere) and the corresponding path lengths associated with incoming and outgoing radiation. Atmospheric absorption by water vapour occurs at many wavelengths whereas absorption by CO2 takes place in three main bands at 2.7, 4.3, and 15 μm (Figure 3). Arrhenius used measurements made by the American physicist Samuel P. Langley in the late 1880s to parameterise absorption, superseding those of Tyndall (Langley had used an instrument of his own invention, the bolometer, to measure the radiation emitted by the full moon at different angles above the horizon).20 Arrhenius divided the earth into latitudinal sections (10 degrees apart) from 70° N to 60° S, with mean surface temperature assigned to each section for each of four seasons. He assigned various parameters for mean cloud amount (0.525), cloud albedo (0.55), snow albedo (0.5–0.78), ocean albedo (0.075), and surface relative humidity (75–80%). These values are acceptable and consistent with parameterisations used in models today.21 He assumed constant relative humidity within the atmosphere, thereby representing the feedback whereby the atmosphere holds more water (with associated absorption of infrared radiation) as it warms. Other feedbacks were not included. The simplicity of the model meant that there was no possibility of representing changes in heat transports due to circulation of the atmosphere and ocean. The cloud fraction remained fixed, as did the relative contributions of land, sea, ice, and cloud to overall albedo.


Download full-size image
Figure 3. Atmospheric absorption spectra for water vapour and CO2. Adapted from Wikimedia Commons.

Arrhenius investigated six scenarios, in which CO2 was set at 0.67, 1.0, 1.5, 2.0, 2.5, and 3.0 times the level in the atmosphere at that time, respectively. The calculations were “tedious,”22 taking up to a year of his time. The result: Arrhenius concluded that a doubling or halving of atmospheric CO2 (now known as the climate sensitivity) would warm or cool the Earth by 5–6 °C. “In order to get the temperature of the Ice Age,” he wrote, “the carbonic acid in the air should sink to 0.62–0.55 of its present value (lowering of temperature 4–5 °C).”23 In fact, Arrhenius's estimate of climate sensitivity is rather too high, which may be due to the atmospheric absorption spectra used in the model. Langley's bolometer was only able to measure accurately at wavelengths less than 3 μm and so excessive absorption, and associated surface heating, may have occurred at longer wavelengths.24 Nevertheless, Arrhenius had successfully presented the case for variations in atmospheric CO2 as a cause of the ice ages.

What, then, of future warming? Arrhenius had, after all, investigated the effects of both decreasing and increasing CO2 on radiative balance. As yet, however, neither he nor his contemporaries had any inkling of the potential detrimental effects of CO2 on climate. Lecturing at the Högskola in 1896, Arrhenius remarked that a doubling of CO2 would occur three-thousand years hence, based on the rate of burning fossil fuel at the time. This would permit, he surmised, “our descendants … to live under a warmer sky and in a less harsh environment than we were granted.”25 In similar fashion, the Swedish meteorologist Nils Ekholm remarked that if “the present burning of pit-coal continues for some thousand years, it will undoubtedly cause a very obvious rise in the mean temperature of the earth. Also Man will no doubt be able to increase the supply of carbonic acid by digging of deep fountains pouring out carbonic acid … [as well as] by protecting the weathering layers of silicates from the influence of the air and by ruling the growth of plants according to his wants and purposes. Thus it seems possible that Man will be able efficaciously to regulate the future climate of the earth and consequently prevent the arrival of a new Ice Age.”26

Callendar: CO2 and twentieth-century warming
The rise of industrialisation was in reality much faster than Arrhenius and Ekholm expected. Society became urbanised and manufacturing continued apace in the early twentieth century as railroads ferried raw materials such as iron and steel to factories where machines now did much of the work. International trade was expanding, fuelled by a growing demand for consumer goods, including new inventions such as the telephone and gasoline powered automobiles. The CO2 story was, however, largely forgotten until Guy Stewart Callendar (Figure 4) emerged on the scene in the 1930s. Callendar was by profession a steam engineer and inventor, second son of Hugh Longbourne Callendar, distinguished professor of physics at Imperial College London. The younger Callendar also took a keen interest in meteorology and, despite ranking as an amateur, was more than a match for his professional counterparts.


Download full-size image
Figure 4. Guy Stewart Callendar in 1934. Credit: Copyright© University of East Anglia, UK. Used with permission.

Callendar, with his expertise in physics, was fully acquainted with Arrhenius's calculations linking global temperature change to atmospheric CO2. Calculations based on theory were all very well, but Callendar wanted proof. Was it possible to show a link between warming and CO2 from measurements made during the previous decades? With his interest in meteorology, Callendar set about compiling the necessary data. He extracted monthly average temperature records from the World Weather Records, a hefty series of volumes published by the Smithsonian Institution.27 After adjusting for the non-uniform geographical distribution of data, he could estimate global temperature based on 147 stations around the world.28 Using this information, Callendar calculated a global increase in land temperatures of about 0.3 °C between 1880 and the late 1930s.29 Measurements of CO2 during this period were not of the uniformly high standard they are today and additional biases occurred in samples taken from inner city areas. The data were scattered throughout the literature of many countries and Callendar selected only those which he thought were representative of clean air,30 calculating a 6% rise in atmospheric CO2 between 1880 and 1935. This increase was, he remarked, consistent with combustion of fossil fuels that had generated about 150 thousand million tonnes of CO2, with three quarters of it having remained in the atmosphere.31 Analysis of ice cores has subsequently vindicated Callendar's early CO2 estimates,32 and it has been shown that his calculations of Earth temperature agree remarkably well with modern estimates for the same period.33

In order to formally establish the physical link between warming and CO2, Callendar sought to apply his expertise in physics to calculate the Earth's heat balance from first principles. He set about constructing a set of equations that was similar to that of Arrhenius, again based on an equilibrium state, but with improvements. He used the infrared absorption spectrum for CO2 of Rubens and Aschkinass,34 rather than Langley's measurements. Unlike Arrhenius, Callendar's model divided the atmosphere into layers, thus representing its vertical structure with respect to temperature, water vapour, and CO2 content. The water vapour feedback was again the only one represented. Like Arrhenius, Callendar undertook calculations for different levels of CO2 in the atmosphere, from which he distilled the results in to a single graph (Figure 5a). Based on the results, Callendar suggested that about half of the warming from 1880–1935 was due to changes in CO2. Moreover, he calculated temperature increase to the end of the twentieth century, although the resulting figure of 0.16 °C35 was considerably too low given that the actual warming was about 0.6 °C.36 The cause of the discrepancy was not, however, because of fundamental deficiencies in Callendar's equations. Rather, he had used estimates of atmospheric CO2 increase that were much too conservative. Furthermore, he considered only CO2 and water vapour when calculating radiative transfer, whereas the role of several other greenhouse gases, including methane, nitrous oxide, and chlorofluorocarbons, is now well known. Aerosols (particulates) released during the burning of fossil fuels are also important because they cause cooling by direct reflection of sunlight and by modification of the optical properties of clouds.37


Download full-size image
Figure 5. Callendar's model relating global annual mean surface air temperature change (ΔT) and atmospheric CO2 and its application (by us) to retrospectively forecast global warming during the twentieth century: (a) ΔT versus pCO2 taken from Callendar's (1938) paper, Callendar, “Artificial Production” (Ref. 29). (To convert x-axis to units of ppm, multiply by 100). The zero-line on the y-axis corresponds to pCO2 of 296 ppm (as measured in 1938). Superimposed is the non-linear regression (dotted red line; Eq. (1)) fitted for pCO2 220–600 ppm; (b) global annual-average (seasonal cycle removed) pCO2 and pCO2-equivalent from observations (“Forcing in GISS Climate Model,” National Aeronautics and Space Administration, accessed 26.05.16, http://data.giss.nasa.gov/modelforce/ghgases); (c) observed progression of ΔT throughout the twentieth century (Colin P. Morice, John J. Kennedy, Nick A. Rayner, and Phil D. Jones, “Quantifying Uncertainties in Global and Regional Temperature Change Using an Ensemble of Observational Estimates: The HadCRUT4 Dataset,” Journal of Geophysical Research 117 (2012): D08101, doi: 10.1029/2011JD017187), with baseline (ΔT = 0) 1880–1935, compared to ΔT predicted using Callendar's model (Eq. (1)) forced with pCO2-equivalent. The visual interpretation of Callendar's model results is slightly complicated by the choice of baseline reference period. We opted for 1880 to 1935, as with Callendar, as this provides a simple visual demonstration of the temperature rise he might have projected for the twentieth century. However, Callendar's reference period was cooled by several volcanic eruptions which are not included in his model and so one could alternatively use a longer reference period, such as 1900–1999, which may be more representative. E. Hawkins and R. Sutton, “Connecting Climate Model Projections of Global Temperature Change with the Real World,” Bulletin of the American Meteorological Society (in press).

What, then, would Callendar have projected for global temperature rise during the twentieth century if he had correctly anticipated the increase in atmospheric CO2, as well as taking into consideration the other greenhouse gases and aerosols? It is possible to undertake this calculation retrospectively using the results of Callendar's equations, as presented in Fig. 5a. In order to do so, we derived an empirical fit to the model (Stephen McIntyre carried out a similar fitting exercise, presented on his Climate Audit website).38 In order to make projections for warming in both the twentieth-century (this section) and the end of the twenty-first century (next section), we fitted a single exponential for the range 220 ≤ pCO2 ≤ 600 ppm (encompassing all pCO2 greater than the preindustrial value of 280 ppm;39pCO2 is the partial pressure of CO2 in air):
(1)
where ΔT is change in surface temperature of the Earth in °C and atmospheric pCO2 is in parts per million (in Callendar's graph, as shown in Figure 5a, it is in parts per ten thousand). The equations indicate that, for today's pCO2 levels in the atmosphere (just over 400 ppm), a doubling of CO2 would lead to a temperature rise of roughly 1.6 °C (Eq. (1); 1.6 = 2.28ln(2)), not accounting for other feedbacks in the climate system.

The effect of the combined suite of greenhouse gases and aerosols on radiative heat balance can be quantified in terms of CO2 equivalent, a metric which scales to common warming potential.40 We imposed this metric (Figure 5b), rather than pCO2 (pCO2 equivalent is less than pCO2 because of aerosols). The resulting projected temperature increase during the twentieth century, using the empirical approximation to Callendar's model (Eq. (1)), is shown in Fig. 5c. Note that the effect of natural changes in heating due to solar output and volcanic activity is not represented. Solar activity increased slightly during the mid-twentieth century,41 promoting heating, whereas the introduction of aerosols (particulates) into the stratosphere by volcanoes caused cooling.42 With these caveats in mind, the projected overall increase in heating is 0.52 °C which is somewhat on the low side compared to the observed rise of 0.6 °C (Fig. 5c), a consequence of Callendar's model (and our empirical approximation of it) not taking account of climate feedbacks (other than water vapour) that amplify warming (see next section). Nevertheless, we conclude that Callendar's model, in conjunction with realistic forcing, performs remarkably well when used to project climate warming during the twentieth century.

Like Arrhenius, Callendar did not foresee the potential detrimental impacts of climate warming. Rather, he emphasised the societal benefits that might accrue from increasing temperature: crop production would be enhanced, especially at northerly latitudes, and the return of another deadly ice age would be delayed indefinitely.43 Indeed, as late as the mid-1950s, the famous cartoonist Virgil Partch was gaily illustrating the coming “revolution in weather” and “boom in the north” (Figure 6).


Download full-size image
Figure 6. Cartoons illustrating the “benefits” of warming climate: (a) the Arctic warms up; (b) nature at last smiles on the Russians; (c) northward migration of animals; (d) drought: water, water – but where? Credit: William J. Baxter and Virgil Partch Today's Revolution in Weather! (New York: International Economic Research Bureau, 1953); William J. Baxter and Virgil Partch, Warmer Weather! … Boom in North (New York: International Economic Research Bureau, 1955).

A source of uncertainty with Callendar's calculations had been the role of the ocean, which, as a reservoir, contains fifty times more carbon than that of the atmosphere. It could be argued that CO2 of industrial origin would not remain in the atmosphere for long but would instead be absorbed and sequestered in this vast storage pool. The idea was refuted by Roger Revelle, an American oceanographer and climate scientist, who demonstrated that, due to the chemical nature of carbon in seawater, the ocean is buffered and can only absorb gases from the atmosphere rather slowly.44 The debate surrounding the dangers of climate warming due to the “invisible pollutant”45 was hotting up. “Human beings,” remarked Revelle, “are now carrying out a large scale geophysical experiment [combustion of fossil fuels] that could not have happened in the past nor be reproduced in future.”46 The International Geophysical Year (IGY) arrived in 1956 and Revelle was joined at the Scripps Institution of Oceanography (San Diego, California) by Charles David Keeling, who was to lead an IGY programme on atmospheric CO2. Keeling thus started the now iconic series of measurements at the Mauna Loa volcano in Hawaii, which have shown the progressive year-on-year increase of CO2 in the atmosphere.47 The dangers of climate change became headline news, with Keeling himself pondering the potential significance “of returning half a billion years’ accumulation of carbon to the air.”48

The future: can we trust Earth System Models?
The advent of digital computers had, by the 1960s, allowed routine weather forecasting, which led in turn to the development of general circulation models for climate simulations.49 Today, projections of climate warming are made using Earth System Models, which in themselves constitute major research programmes. Run on supercomputers, the code alone reaches hundreds of thousands of lines. (It is worth noting that similar code describing the atmosphere is used in weather forecasting models, which are successfully tested every day, thereby providing extra credibility for some of the parameterisations involved.) The need for all this computing muscle is unsurprising given that the Earth system is outwardly complex, involving a myriad of processes and interactions between land, oceans, and the atmosphere (Figure 7). ESMs divide the global domain into a matrix of grid cells, within which the three-dimensional fluxes of heat, water, and carbon are simulated. Regional interactions and their impact on the global system are thereby represented. Climate feedbacks are centre stage including changes in atmospheric and ocean circulation, melting of snow and ice, fertilisation of vegetation by CO2, changes to clouds and water vapour.


Download full-size image
Figure 7. The climate system. Copyright© University Corporation for Atmospheric Research. Illustration by Paul Grabhorn.

Source: Warren M. Washington, Lawrence Buja, and Anthony Craig, “The Computational Future for Climate and Earth System Models: On the Path to Petaflop and Beyond,” Philosophical Transactions of the Royal Society A 367 (2009): 833–46. Used with permission.
In the last section, we showed that Callendar's equations, with no representation of feedbacks with the exception of water vapor, could potentially explain most of the warming observed during the twentieth century. This poses the obvious question: do we actually need the ESMs? This is a somewhat hypothetical question, as there is the obvious rejoinder that we need more than just projections of global average climate. The spatial grid of ESMs provides geographical detail of future changes, essential information for developing adaptation and mitigation strategies at regional scales. Nevertheless, with respect to the global domain, one can still ask whether it is necessary to include all the extra complexity, including feedbacks, in models in order to make projections of climate warming. And if the extra complexity is necessary, to what extent does it introduce uncertainty into the projected outcomes? In order to answer these questions, we examine the projections of climate warming during the twenty-first century generated by a suite of ESMs as published in the latest IPCC assessment report.50 Results are presented for two contrasting Representative Concentration Pathway (RCP) scenarios,51 RCPs 2.6 and 8.5, which specify future emissions of greenhouse gases and aerosols. The former is a strong mitigation scenario involving major replacement of fossil fuel use with renewable energies and nuclear power, as well as the implementation of new technologies for carbon capture and storage.52 In contrast, RCP 8.5 is a high emission scenario that assumes rapid population growth, along with modest improvements in the efficiency of energy usage, and so ongoing high demand for energy from fossil fuels;53 atmospheric CO2 more than doubles from its present day value of just over 400–936 ppm by the year 2100.

The projected increase in global surface temperature during the course of the twenty-first century by the ESMs is 1.0 and 3.7 °C for RCPs 2.6 and 8.5 respectively, based on the ensemble means of the simulations (Figure 8). There is, however, considerable spread across the ESMs for each scenario; 95% confidence intervals are 0.3–1.7 °C for RCP 2.6 and 2.6–4.8 °C for RCP 8.5.54 This range indicates uncertainty in the results that can be understood, we propose, by separating warming into two components: baseline warming due to the physics of radiative transfer (the “greenhouse effect”) and additional warming due to climate feedbacks. The baseline component of total warming, as projected by the ESMs, can be quantified by analogy using Callendar's model assuming that both share essentially the same equations for the core physics of radiative transfer (and noting the Callendar's model contains one feedback, water vapour, which is therefore considered part of the baseline). We therefore used Eq. (1) (the empirical approximation of Callendar's model) to project future baseline warming, again forced with CO2 equivalent. The resulting end-of-century warming is 0.4 and 2.8 °C for RCPs 2.6 and 8.5 respectively (Figure 8), on the lower bound of the total warming projected by the ESMs, which includes not only the baseline, but also extra warming due to feedbacks. These projections of baseline warming are, we argue, quantitatively robust (i.e., trustworthy) because the core physics of radiative transfer is conceptually simple with no major uncertainties and can be relatively straightforwardly described in mathematics. There is one caveat: the Earth system is currently not in a state of radiative equilibrium, which is contrary to the equilibrium assumption of Callendar's model. This disequilibrium is principally due to the timescale of climate feedbacks, but also occurs because the ocean is a vast store of heat. As heat from the atmosphere penetrates surface waters, some causes direct warming on timescales up to about fifteen years, whereas some is mixed into the deep ocean and will only return to the surface and thereby reach thermal equilibrium with the atmosphere on timescales of centuries or more. The deep ocean thus heats up relatively slowly and the use of Callendar's model will therefore overestimate the baseline warming generated by the ESMs on timescales of several decades. The error associated with thermal inertia would appear, however, to be relatively small, e.g. up to 0.4 °C by the end of the twenty-first century (for RCP 8.5 and much less for RCP 2.6).55


Download full-size image
Figure 8. (a) CMIP-5 intercomparison: twenty-first century ensemble projections of Earth temperature for RCPs 2.6 (blue) and 8.5 (red) emissions scenarios (thin lines), with projections based on Callendar's model (forced using CO2-equivalent) (Eq. (1)) superimposed (thick lines); (b) Likely ranges of temperature change by the end of the twenty-first century for four RCP scenarios (years 2081–2100 relative to 1986–2005). The range of results of the model ensemble are also shown for two intermediate scenarios, RCP 4.5 and RCP 6.0. IPCC, Climate Change 2013 (Ref. 2).

Over and above the baseline, additional warming is projected by the ESMs due to climate feedbacks. Thus, the extra complexity of the climate system does matter. We do need the ESMs. Unlike the quantitatively robust core physics, however, there is considerable uncertainty in the magnitude of climate feedbacks, which is manifest as the spread of projections within the model ensemble. Nevertheless, although uncertain in magnitude, the sign of the temperature response is known: positive. Based on decades of high quality research, the evidence firmly points to amplification of warming by climate feedbacks. The potential for the atmosphere to hold water vapor increases with warming, melting of snow and ice lowers albedo, CO2 uptake by plants is diminished as other factors limit growth, and production by plankton decreases as a warming ocean supplies less nutrients to surface waters.56 There are uncertainties, of which the largest may be associated with clouds and how they change in future.57 The case for the overall impact of feedbacks being positive (i.e., amplification of warming) is nevertheless overwhelming.58 Some feedbacks operate over long timescales, such as the melting of ice sheets and glaciers and changes in vegetation,59 and so, as with the thermal inertia of the ocean, mean that the system is not in equilibrium. This does not, however, compromise our analysis of the uncertainties in the projections of climate warming by ESMs because the models directly incorporate the full time dependency of the processes involved.

We conclude that the projections of end-of-century global warming by ESMs are essentially trustworthy: quantitatively robust baseline warming driven by the core physics of radiative transfer, with extra warming due to climate feedbacks. Any notion that the climate system is too complex for meaningful analysis, or that the climate warming projections of ESMs are not plausible or relevant, can be discounted. The projections of ESMs provide a compelling case that global climate will continue to undergo significant warming in response to ongoing emissions of greenhouse gases to the atmosphere. Arrhenius and Callendar demonstrated admirably that core physics can explain much of the observed variation in global surface temperature as a consequence of changes in atmospheric CO2. With their work providing the foundation, we have shown that the conceptual separation of the processes associated with the radiative core of the greenhouse and climate feedbacks is the key to understanding the overall uncertainty, and associated trustworthiness, of climate models. In closing, we should reiterate that warming at global scale is by no means the sole focus of climate research. Regional climate matters also, necessitating the use of the ESMs, which provide the required geographical resolution, representation of mountains, oceans and land-types, and other information. Projections at regional scale focus not only on warming, but also on the incidence of extreme events such as floods, droughts, and hurricanes. A discussion of the merits of ESMs in making projections of regional climate is beyond the scope of this article; suffice to say that providing robust simulations of the global trend in warming is an excellent starting point.

Acknowledgments
TRA is funded by the National Environment Research Council (NERC), UK. EH is supported by a NERC Advanced Research Fellowship and by the National Centre for Atmospheric Science. We wish to thank two anonymous reviewers for their helpful and informative comments on the manuscript.